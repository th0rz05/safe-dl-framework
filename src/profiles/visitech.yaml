attack_overrides:
  backdoor:
    static_patch:
      blend_alpha: 1.0
      label_mode: corrupted
      patch_position: bottom_right
      patch_size_ratio: 0.15
      patch_type: white_square
      poison_fraction: 0.05
      target_class: 7
  data_poisoning:
    label_flipping:
      flip_rate: 0.08
      source_class: null
      strategy: many_to_one
      target_class: 9
  evasion:
    pgd:
      alpha: 0.01
      epsilon: 0.03
      max_samples: 1000
      num_iter: 50
      random_start: true
    spsa:
      batch_size: 32
      delta: 0.01
      epsilon: 0.03
      learning_rate: 0.01
      max_samples: 500
      num_steps: 150
dataset:
  name: cifar10
  type: builtin
defense_config:
  backdoor:
    static_patch:
      activation_clustering:
        num_clusters: 2
      anomaly_detection:
        type: isolation_forest
      defenses:
      - activation_clustering
      - spectral_signatures
      - anomaly_detection
      - pruning
      - fine_pruning
      - model_inspection
      fine_pruning:
        pruning_ratio: 0.2
      model_inspection:
        layers:
        - conv.0.weight
        - conv.0.bias
        - fc.1.weight
        - fc.1.bias
      pruning:
        pruning_ratio: 0.2
        scope: all_layers
      spectral_signatures:
        threshold: 0.9
  data_poisoning:
    clean_label:
      defenses:
      - provenance_tracking
      - influence_functions
      influence_functions:
        method: grad_influence
        sample_size: 500
      provenance_tracking:
        granularity: sample
    label_flipping:
      data_cleaning:
        method: loss_filtering
        threshold: 0.9
      defenses:
      - data_cleaning
      - per_class_monitoring
      - robust_loss
      - dp_training
      dp_training:
        clip_norm: 1.0
        delta: 1.0e-05
        epsilon: 2.0
      per_class_monitoring:
        std_threshold: 2.0
      robust_loss:
        type: gce
  evasion:
    pgd:
      adversarial_training:
        attack_type: fgsm
        epsilon: 0.03
      defenses:
      - adversarial_training
      - randomized_smoothing
      randomized_smoothing:
        sigma: 0.25
    spsa:
      defenses:
      - gradient_masking
      - jpeg_preprocessing
      gradient_masking:
        strength: 0.5
      jpeg_preprocessing:
        quality: 75
model:
  input_shape:
  - 3
  - 32
  - 32
  name: resnet18
  num_classes: 10
  type: builtin
name: visitech
risk_analysis:
  recommendations:
    label_flipping:
    - data_cleaning
    - per_class_monitoring
    pgd:
    - adversarial_training
    - randomized_smoothing
    spsa:
    - gradient_masking
    - jpeg_preprocessing
    static_patch:
    - activation_clustering
    - spectral_signatures
  summary:
    label_flipping:
      probability: 1.0
      risk_score: 0.787
      severity: 0.572
      visibility: 0.624
    pgd:
      probability: 1.0
      risk_score: 1.7
      severity: 1.0
      visibility: 0.3
    spsa:
      probability: 0.8
      risk_score: 1.44
      severity: 1.0
      visibility: 0.2
    static_patch:
      probability: 1.0
      risk_score: 0.461
      severity: 0.33
      visibility: 0.6
threat_model:
  attack_goal: targeted
  data_sensitivity: high
  deployment_scenario: cloud
  interface_exposed: api
  model_access: white-box
  model_type: cnn
  threat_categories:
  - data_poisoning
  - backdoor_attacks
  - evasion_attacks
  - model_stealing
  - membership_inference
  - model_inversion
  training_data_source: internal_clean
