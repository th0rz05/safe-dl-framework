attack_overrides:
  data_poisoning:
    clean_label:
      epsilon: 0.1
      fraction_poison: 0.05
      max_iterations: 100
      perturbation_method: feature_collision
      source_selection: random
      target_class: 2
    label_flipping:
      flip_rate: 0.08
      source_class: null
      strategy: many_to_one
      target_class: 6
dataset:
  name: cifar10
  type: builtin
defense_config:
  backdoor: {}
  data_poisoning:
    label_flipping:
      data_cleaning:
        method: loss_filtering
        threshold: 0.9
      defenses:
      - data_cleaning
      dp_training:
        clip_norm: 1.0
        delta: 1.0e-05
        epsilon: 2.0
      per_class_monitoring:
        std_threshold: 2.0
      robust_loss:
        type: gce
  evasion_attacks: {}
model:
  input_shape:
  - 3
  - 32
  - 32
  name: cnn
  num_classes: 10
  params:
    conv_filters: 32
    hidden_size: 128
  type: builtin
name: test
risk_analysis:
  recommendations:
    clean_label:
    - provenance_tracking
    - influence_functions
    cw:
    - adversarial_training
    - randomized_smoothing
    deepfool:
    - adversarial_training
    - randomized_smoothing
    fgsm:
    - adversarial_training
    - randomized_smoothing
    label_flipping:
    - data_cleaning
    - per_class_monitoring
    learned_trigger:
    - activation_clustering
    - spectral_signatures
    - fine_pruning
    - model_inspection
    nes:
    - gradient_masking
    - jpeg_preprocessing
    pgd:
    - adversarial_training
    - randomized_smoothing
    spsa:
    - gradient_masking
    - jpeg_preprocessing
    transfer:
    - adversarial_training
    - randomized_smoothing
  summary:
    clean_label:
      probability: 0.9
      risk_score: 0.244
      severity: 0.159
      visibility: 0.3
    cw:
      probability: 0.9
      risk_score: 1.53
      severity: 1.0
      visibility: 0.3
    deepfool:
      probability: 1.0
      risk_score: 1.9
      severity: 1.0
      visibility: 0.1
    fgsm:
      probability: 1.0
      risk_score: 1.7
      severity: 1.0
      visibility: 0.3
    label_flipping:
      probability: 1.0
      risk_score: 0.547
      severity: 0.422
      visibility: 0.705
    learned_trigger:
      probability: 0.9
      risk_score: 1.62
      severity: 1.0
      visibility: 0.2
    nes:
      probability: 0.8
      risk_score: 1.44
      severity: 1.0
      visibility: 0.2
    pgd:
      probability: 1.0
      risk_score: 1.7
      severity: 1.0
      visibility: 0.3
    spsa:
      probability: 0.8
      risk_score: 1.44
      severity: 1.0
      visibility: 0.2
    static_patch:
      probability: 1.0
      risk_score: 1.4
      severity: 1.0
      visibility: 0.6
    transfer:
      probability: 0.85
      risk_score: 1.53
      severity: 1.0
      visibility: 0.2
threat_model:
  attack_goal: targeted
  data_sensitivity: high
  deployment_scenario: cloud
  interface_exposed: api
  model_access: white-box
  model_type: cnn
  threat_categories:
  - data_poisoning
  - backdoor_attacks
  - evasion_attacks
  - model_stealing
  - membership_inference
  - model_inversion
  training_data_source: internal_clean
