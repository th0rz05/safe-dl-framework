attack_overrides:
  data_poisoning:
    label_flipping:
      flip_rate: 0.08
      source_class: null
      strategy: many_to_one
      target_class: 0
dataset:
  name: cifar10
  type: builtin
defense_config:
  backdoor:
    learned_trigger:
      activation_clustering:
        num_clusters: 2
      defenses:
      - activation_clustering
      - spectral_signatures
      - fine_pruning
      - model_inspection
      fine_pruning:
        pruning_ratio: 0.2
      model_inspection:
        layers:
        - fc1
        - fc2
      spectral_signatures:
        threshold: 0.9
  data_poisoning:
    clean_label:
      defenses:
      - provenance_tracking
      - influence_functions
      influence_functions:
        method: grad_influence
        sample_size: 500
      provenance_tracking:
        granularity: sample
    label_flipping:
      defenses:
      - robust_loss
      - dp_training
      dp_training:
        clip_norm: 1.0
        delta: 1.0e-05
        epsilon: 2.0
      robust_loss:
        type: gce
  evasion_attacks:
    cw:
      adversarial_training:
        attack_type: fgsm
        epsilon: 0.03
      certified_defense:
        method: interval_bound
      defenses:
      - adversarial_training
      - randomized_smoothing
      - certified_defense
      randomized_smoothing:
        sigma: 0.25
    deepfool:
      adversarial_training:
        attack_type: fgsm
        epsilon: 0.03
      certified_defense:
        method: interval_bound
      defenses:
      - adversarial_training
      - randomized_smoothing
      - certified_defense
      randomized_smoothing:
        sigma: 0.25
    fgsm:
      adversarial_training:
        attack_type: fgsm
        epsilon: 0.03
      certified_defense:
        method: interval_bound
      defenses:
      - adversarial_training
      - randomized_smoothing
      - certified_defense
      randomized_smoothing:
        sigma: 0.25
    nes:
      defenses:
      - gradient_masking
      - jpeg_preprocessing
      gradient_masking:
        strength: 0.5
      jpeg_preprocessing:
        quality: 75
    pgd:
      adversarial_training:
        attack_type: fgsm
        epsilon: 0.03
      certified_defense:
        method: interval_bound
      defenses:
      - adversarial_training
      - randomized_smoothing
      - certified_defense
      randomized_smoothing:
        sigma: 0.25
    spsa:
      defenses:
      - gradient_masking
      - jpeg_preprocessing
      gradient_masking:
        strength: 0.5
      jpeg_preprocessing:
        quality: 75
    transfer:
      adversarial_training:
        attack_type: fgsm
        epsilon: 0.03
      certified_defense:
        method: interval_bound
      defenses:
      - adversarial_training
      - randomized_smoothing
      - certified_defense
      randomized_smoothing:
        sigma: 0.25
model:
  input_shape:
  - 3
  - 32
  - 32
  name: cnn
  num_classes: 10
  params:
    conv_filters: 32
    hidden_size: 128
  type: builtin
name: test
risk_analysis:
  recommendations:
    clean_label:
    - provenance_tracking
    - influence_functions
    - monitor_drift
    cw:
    - adversarial_training
    - randomized_smoothing
    - certified_defense
    deepfool:
    - adversarial_training
    - randomized_smoothing
    - certified_defense
    fgsm:
    - adversarial_training
    - randomized_smoothing
    - certified_defense
    label_flipping:
    - data_cleaning
    - per_class_monitoring
    learned_trigger:
    - activation_clustering
    - spectral_signatures
    - fine_pruning
    - model_inspection
    nes:
    - gradient_masking
    - jpeg_preprocessing
    pgd:
    - adversarial_training
    - randomized_smoothing
    - certified_defense
    spsa:
    - gradient_masking
    - jpeg_preprocessing
    transfer:
    - adversarial_training
    - randomized_smoothing
    - certified_defense
  summary:
    clean_label:
      probability: 0.9
      risk_score: 0.244
      severity: 0.159
      visibility: 0.3
    cw:
      probability: 0.9
      risk_score: 1.53
      severity: 1.0
      visibility: 0.3
    deepfool:
      probability: 1.0
      risk_score: 1.9
      severity: 1.0
      visibility: 0.1
    fgsm:
      probability: 1.0
      risk_score: 1.7
      severity: 1.0
      visibility: 0.3
    label_flipping:
      probability: 1.0
      risk_score: 0.547
      severity: 0.422
      visibility: 0.705
    learned_trigger:
      probability: 0.9
      risk_score: 1.62
      severity: 1.0
      visibility: 0.2
    nes:
      probability: 0.8
      risk_score: 1.44
      severity: 1.0
      visibility: 0.2
    pgd:
      probability: 1.0
      risk_score: 1.7
      severity: 1.0
      visibility: 0.3
    spsa:
      probability: 0.8
      risk_score: 1.44
      severity: 1.0
      visibility: 0.2
    static_patch:
      probability: 1.0
      risk_score: 1.4
      severity: 1.0
      visibility: 0.6
    transfer:
      probability: 0.85
      risk_score: 1.53
      severity: 1.0
      visibility: 0.2
threat_model:
  attack_goal: targeted
  data_sensitivity: high
  deployment_scenario: cloud
  interface_exposed: api
  model_access: white-box
  model_type: cnn
  threat_categories:
  - data_poisoning
  - backdoor_attacks
  - evasion_attacks
  - model_stealing
  - membership_inference
  - model_inversion
  training_data_source: internal_clean
