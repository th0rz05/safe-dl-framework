attack_overrides:
  backdoor:
    static_patch:
      blend_alpha: 1.0
      label_mode: corrupted
      patch_position: bottom_right
      patch_size_ratio: 0.15
      patch_type: white_square
      poison_fraction: 0.05
      target_class: 7
  data_poisoning:
    clean_label:
      epsilon: 0.1
      fraction_poison: 0.05
      max_iterations: 100
      perturbation_method: feature_collision
      source_selection: random
      target_class: 5
    label_flipping:
      flip_rate: 0.08
      source_class: null
      strategy: many_to_one
      target_class: 1
  evasion:
    pgd:
      alpha: 0.01
      epsilon: 0.03
      num_iter: 50
      random_start: true
    spsa:
      batch_size: 32
      delta: 0.01
      epsilon: 0.03
      learning_rate: 0.01
      max_samples: 500
      num_steps: 150
dataset:
  name: cifar10
  type: builtin
defense_config:
  backdoor:
    static_patch:
      activation_clustering:
        num_clusters: 2
      anomaly_detection:
        type: isolation_forest
      defenses:
      - activation_clustering
      - spectral_signatures
      - anomaly_detection
      - pruning
      - fine_pruning
      - model_inspection
      fine_pruning:
        pruning_ratio: 0.2
      model_inspection:
        layers:
        - conv.0.weight
        - conv.0.bias
        - fc.1.weight
        - fc.1.bias
      pruning:
        pruning_ratio: 0.2
        scope: all_layers
      spectral_signatures:
        threshold: 0.9
  data_poisoning:
    clean_label:
      defenses:
      - provenance_tracking
      - influence_functions
      influence_functions:
        method: grad_influence
        sample_size: 500
      provenance_tracking:
        granularity: sample
    label_flipping:
      data_cleaning:
        method: loss_filtering
        threshold: 0.9
      defenses:
      - data_cleaning
      - per_class_monitoring
      - robust_loss
      - dp_training
      dp_training:
        clip_norm: 1.0
        delta: 1.0e-05
        epsilon: 2.0
      per_class_monitoring:
        std_threshold: 2.0
      robust_loss:
        type: gce
  evasion:
    pgd:
      adversarial_training:
        attack_type: fgsm
        epsilon: 0.03
      defenses:
      - adversarial_training
      - randomized_smoothing
      randomized_smoothing:
        sigma: 0.25
    spsa:
      defenses:
      - gradient_masking
      - jpeg_preprocessing
      gradient_masking:
        strength: 0.5
      jpeg_preprocessing:
        quality: 75
model:
  input_shape:
  - 3
  - 32
  - 32
  name: cnn
  num_classes: 10
  params:
    conv_filters: 32
    hidden_size: 128
  type: builtin
name: test
risk_analysis:
  recommendations:
    clean_label:
    - provenance_tracking
    - influence_functions
    cw:
    - adversarial_training
    - randomized_smoothing
    deepfool:
    - adversarial_training
    - randomized_smoothing
    fgsm:
    - adversarial_training
    - randomized_smoothing
    label_flipping:
    - data_cleaning
    - per_class_monitoring
    learned_trigger:
    - activation_clustering
    - spectral_signatures
    - fine_pruning
    - model_inspection
    nes:
    - gradient_masking
    - jpeg_preprocessing
    pgd:
    - adversarial_training
    - randomized_smoothing
    spsa:
    - gradient_masking
    - jpeg_preprocessing
    transfer:
    - adversarial_training
    - randomized_smoothing
  summary:
    clean_label:
      probability: 0.9
      risk_score: 0.244
      severity: 0.159
      visibility: 0.3
    cw:
      probability: 0.9
      risk_score: 1.53
      severity: 1.0
      visibility: 0.3
    deepfool:
      probability: 1.0
      risk_score: 1.9
      severity: 1.0
      visibility: 0.1
    fgsm:
      probability: 1.0
      risk_score: 1.7
      severity: 1.0
      visibility: 0.3
    label_flipping:
      probability: 1.0
      risk_score: 0.547
      severity: 0.422
      visibility: 0.705
    learned_trigger:
      probability: 0.9
      risk_score: 1.62
      severity: 1.0
      visibility: 0.2
    nes:
      probability: 0.8
      risk_score: 1.44
      severity: 1.0
      visibility: 0.2
    pgd:
      probability: 1.0
      risk_score: 1.7
      severity: 1.0
      visibility: 0.3
    spsa:
      probability: 0.8
      risk_score: 1.44
      severity: 1.0
      visibility: 0.2
    static_patch:
      probability: 1.0
      risk_score: 1.4
      severity: 1.0
      visibility: 0.6
    transfer:
      probability: 0.85
      risk_score: 1.53
      severity: 1.0
      visibility: 0.2
threat_model:
  attack_goal: targeted
  data_sensitivity: high
  deployment_scenario: cloud
  interface_exposed: api
  model_access: white-box
  model_type: cnn
  threat_categories:
  - data_poisoning
  - backdoor_attacks
  - evasion_attacks
  - model_stealing
  - membership_inference
  - model_inversion
  training_data_source: internal_clean
