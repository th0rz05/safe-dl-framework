# Evasion Attack Report — PGD

## Overview

- **Attack Type:** pgd
- **Epsilon:** 0.03
- **Alpha (step size):** 0.01
- **Number of Iterations:** 50
- **Random Start:** True

## Performance Metrics

- **Accuracy on Clean Test Set (CDA):** 0.6754
- **Accuracy on Adversarial Test Set (ADA):** 0.0000

### Per‑Class Accuracy (Clean Test Set)

| Class | Accuracy |
|-------|----------|
| airplane | 0.6720 |
| automobile | 0.7830 |
| bird | 0.6380 |
| cat | 0.3570 |
| deer | 0.6360 |
| dog | 0.6080 |
| frog | 0.6940 |
| horse | 0.7840 |
| ship | 0.8620 |
| truck | 0.7200 |

### Per‑Class Accuracy (Adversarial Test Set)

| Class | Accuracy |
|-------|----------|
| airplane | 0.0000 |
| automobile | 0.0000 |
| bird | 0.0000 |
| cat | 0.0000 |
| deer | 0.0000 |
| dog | 0.0000 |
| frog | 0.0000 |
| horse | 0.0000 |
| ship | 0.0000 |
| truck | 0.0000 |

## Example Adversarial Samples

The following examples illustrate adversarial inputs generated by the PGD attack. Each image is named using the format:

```
pgd<index>_<true_class>_<pred_adv_class>.png
```
- `<index>`: Sample index in the test set.
- `<true_class>`: Ground truth label.
- `<pred_adv_class>`: Predicted label after attack.

<div style="display: flex; gap: 10px;">
<div style="text-align:center;"><small>examples/pgd_0_cat_ship.png</small><br><img src="examples/pgd_0_cat_ship.png" style="width: 120px;"></div>
<div style="text-align:center;"><small>examples/pgd_1_ship_automobile.png</small><br><img src="examples/pgd_1_ship_automobile.png" style="width: 120px;"></div>
<div style="text-align:center;"><small>examples/pgd_2_ship_airplane.png</small><br><img src="examples/pgd_2_ship_airplane.png" style="width: 120px;"></div>
<div style="text-align:center;"><small>examples/pgd_3_airplane_ship.png</small><br><img src="examples/pgd_3_airplane_ship.png" style="width: 120px;"></div>
<div style="text-align:center;"><small>examples/pgd_4_frog_deer.png</small><br><img src="examples/pgd_4_frog_deer.png" style="width: 120px;"></div>
</div>